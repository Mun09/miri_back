"""
Investigator Module - Legal Research and Evidence Collection
ë²•ë¥  ì¡°ì‚¬ ë° ì¦ê±° ìˆ˜ì§‘ ëª¨ë“ˆ
"""
import re
import asyncio
import json_repair
from typing import List, Dict, Tuple, Optional, Callable, Any

from models import SearchStrategy, AtomicAction, Scenario, LegalEvidence, DocumentReview
from llm_client import llm_client
from law_api import law_api
from config import MAX_ANALYSIS_DOCS


class Investigator:
    """
    Expert Investigator with Self-Correction (Critic) & Action-Based Search & Strategic Planning
    """
    
    STRATEGY_PROMPT = """
    Analyze the legal nature of the following action/situation to decide the optimal search strategy.

    [Action/Situation]
    {action}

    [Database Characteristics]
    - law (Acts, Decrees): For legal prohibitions, permissions, obligations, civil/criminal liabilities, and penalties.
    - admrul (Administrative Rules): For specific criteria, monetary limits, procedures, and detailed guidelines.
    - prec (Precedents): For case law interpretations, similar dispute resolutions, and judicial standards.

    [Instructions]
    1. Determine if this is: business regulation, contract law, criminal law, civil dispute, labor law, or general legal matter
    2. If criminal/civil liability is involved, prioritize 'law' and 'prec'
    3. If specific procedures or quantitative standards matter, include 'admrul'
    4. For disputes or interpretation issues, include 'prec'
    5. List databases in order of importance
    6. Add 'Focus Keywords' for comprehensive search coverage
    
    Output JSON:
    {{
        "rationale": "Reason for this strategy (English)",
        "databases": ["law", "admrul", "prec"],
        "focus_keywords": ["KoreanKeyWord1", "KoreanKeyWord2"]
    }}
    
    [Important]
    "focus_keywords" MUST be in KOREAN.
    """

    EXPANSION_PROMPT = """
    User situation/action: '{action}' (Target: {object})
    
    Extract 3-5 SPECIFIC LEGAL KEYWORDS for finding relevant Korean laws.
    
    [Strategy]
    Analyze the legal domain:
    1. What laws GOVERN or REGULATE this action/situation?
    2. What LEGAL RIGHTS, OBLIGATIONS, or LIABILITIES are involved?
    3. What SPECIFIC LEGAL TERMS are used in Korean law for this matter?
    4. Consider: civil law, criminal law, special laws, labor law, commercial law, etc.
    
    [Examples - Be SPECIFIC and DOMAIN-APPROPRIATE]
    âœ“ Good (Specific Legal Terms):
      * "Unfair dismissal" â†’ ["ë¶€ë‹¹í•´ê³ ", "ê·¼ë¡œê¸°ì¤€", "í•´ê³ ì˜ˆê³ "]
      * "Breach of contract" â†’ ["ê³„ì•½ìœ„ë°˜", "ì†í•´ë°°ìƒ", "ì±„ë¬´ë¶ˆì´í–‰"]
      * "Personal injury accident" â†’ ["ë¶ˆë²•í–‰ìœ„", "ê³¼ì‹¤", "ì†í•´ë°°ìƒ"]
      * "Consumer fraud" â†’ ["ì†Œë¹„ìë³´í˜¸", "ê¸°ë§Œí–‰ìœ„", "ì•½ê´€ê·œì œ"]
      * "Currency exchange platform" â†’ ["ì™¸êµ­í™˜", "ì „ìê¸ˆìœµ", "í™˜ì „"]
      * "Privacy violation" â†’ ["ê°œì¸ì •ë³´", "ì •ë³´í†µì‹ ", "ëª…ì˜ˆí›¼ì†"]
      * "Real estate dispute" â†’ ["ë¶€ë™ì‚°", "ì„ëŒ€ì°¨", "ì†Œìœ ê¶Œ"]
    
    âœ— Bad (Too generic or non-legal):
      * "Contract issue" â†’ ["ê³„ì•½", "ë¬¸ì œ"] â† TOO VAGUE
      * "Money problem" â†’ ["ëˆ", "ê¸ˆì „"] â† NOT LEGAL TERMS
    
    [Important]
    - Keywords MUST be in KOREAN
    - Focus on LEGAL TERMS that appear in statutes, not everyday language
    - Think about civil/criminal liability, rights, obligations, prohibitions
    - Single nouns without particles (No 'ì„', 'ë¥¼', 'ì˜')
    - Return JSON array of 3-5 strings
    
    Output format: ["ë²•ë¥ ìš©ì–´1", "ë²•ë¥ ìš©ì–´2", "ë²•ë¥ ìš©ì–´3"]
    """

    SELECTOR_PROMPT = """
    You are an expert 'Legal Researcher' responsible for selecting relevant laws and precedents.
    
    [Task]
    Review the provided list of law/precedent titles and select ALL items that are RELEVANT to the user's situation.
    
    [Selection Criteria]
    1. Direct Relevance: The title explicitly mentions the issue (e.g., "unfair dismissal", "hit-and-run").
    2. Broader Relevance: The law governs the domain (e.g., "Labor Standards Act" for firing).
    3. Be Generous: If in doubt, INCLUDE it. It's better to analyze more than to miss critical evidence.
    
    [Input Format]
    User will provide:
    - User Action/Scenario
    - List of Candidates (numbered)

    [Output Format]
    Return ONLY a JSON array of the exact strings (names) selected from the list.
    Example: ["Title 1", "Title 3"]
    
    If NONE are relevant, return: []
    """

    KEYWORD_GEN_PROMPT = """
    User Situation/Action: "{action}"
    Infer 5 core legal keywords for comprehensive case law and precedent search.
    
    [Important]
    **Keywords MUST be in KOREAN** (Hangul).
    The search engine only understands Korean legal terms.

    Focus on:
    1. Specific illegal acts or violations (e.g., "ë¬´ë‹¨ì‚¬ìš©", "ë¬´ë“±ë¡ì˜ì—…", "ì‚¬ê¸°")
    2. Legal concepts for disputes (e.g., "ì†í•´ë°°ìƒ", "ê³„ì•½í•´ì œ", "ë¶€ë‹¹ì´ë“")
    3. Rights and obligations (e.g., "í‡´ì§ê¸ˆ", "ë³´ì¦ê¸ˆë°˜í™˜", "ìœ„ìë£Œ")
    4. Procedural terms if relevant (e.g., "ê°€ì²˜ë¶„", "ì¤‘ì¬", "ì¡°ì •")
    
    Examples by type:
    - Business: "ë¬´ë“±ë¡", "ë¶ˆë²•ì˜ì—…", "ì¸í—ˆê°€ìœ„ë°˜"
    - Contract: "ì±„ë¬´ë¶ˆì´í–‰", "ê³„ì•½í•´ì œ", "ì†í•´ë°°ìƒ"
    - Labor: "ë¶€ë‹¹í•´ê³ ", "ì„ê¸ˆì²´ë¶ˆ", "ê·¼ë¡œê¸°ì¤€ìœ„ë°˜"
    - Real Estate: "ëª…ë„", "ì„ëŒ€ì°¨ë³´í˜¸", "ë³´ì¦ê¸ˆ"
    - Criminal: "ì‚¬ê¸°", "íš¡ë ¹", "ë°°ì„"
    
    Output as a JSON list of Korean strings: ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", ...]
    """

    AI_QUERY_PROMPT = """
    [Task] Generate effective search queries for the 'Intelligent Bureau of Legislation Search System' (AI Search).
    
    [User Action/Scenario]
    {action}
    
    [Instructions]
    - The AI Search system handles natural language but performs best with "KEY PHRASES" that describe the legal violation or topic.
    - Generate 2-3 queries.
    - Queries MUST be in KOREAN.
    - Example: "ëº‘ì†Œë‹ˆ ì²˜ë²Œ", "ìŒì£¼ìš´ì „ ë©´í—ˆì·¨ì†Œ ê¸°ì¤€", "ê°œì¸ì •ë³´ ìœ ì¶œ ê³¼íƒœë£Œ"
    
    Output JSON: ["query1", "query2"]
    """

    CRITIC_PROMPT = """
    [Review Mode]
    User Action: "{action}"
    Current list of secured legal evidence:
    {evidence_summary}

    Q: Can the user's action be judged through 'legal interpretation' based solely on the evidence above?

    [PASS Criteria (Relaxed)]
    - If there are similar regulations or general principles, even without explicit provisions â†’ PASS
    - If there are related limit concepts or reporting obligations, even without specific amounts â†’ PASS
    - If reasonable inference is possible from laws alone, even without precedents â†’ PASS
    - If there are prohibition/restriction clauses, even without penalty clauses â†’ PASS

    [FAIL Criteria]
    - If no relevant laws were found at all (completely different field)
    - If too abstract to interpret in any direction

    If sufficient, output "PASS". If clearly insufficient, output "FAIL" along with suggested additional keywords.

    Output JSON Format:
    {{
        "status": "PASS" | "FAIL",
        "reason": "Reason (English)",
        "new_keywords": ["keyword1", "keyword2"]
    }}
    """

    PROMPTS = {
        "law": "[Law Analysis] Core: Find clauses (Article X) in this law that prohibit or restrict the user's action.",
        "admrul": "[Administrative Rule Analysis] Core: Find specific approval criteria, monetary limits, and reporting procedure figures.",
        "prec": "[Precedent Analysis] Core: Find the gist and applied legal principles of judgments (guilty/not guilty) for similar actions."
    }

    def __init__(self):
        # [NEW] ë¶„ì„ ê²°ê³¼ ìºì‹œ (LLM ë¹„ìš© ì ˆê°)
        self._analysis_cache = {}

    async def _plan_search(self, action: AtomicAction) -> SearchStrategy:
        prompt = self.STRATEGY_PROMPT.format(action=action.action)
        # [MODEL: GPT-4o-mini] ê²€ìƒ‰ ì „ëµ ìˆ˜ë¦½ (ë¹„ìš© ì ˆê°)
        response = await llm_client.generate("", prompt, model="gpt-4o-mini", max_tokens=512)
        try:
            data = json_repair.loads(response)
            return SearchStrategy(**data)
        except Exception as e:
            print(f"      âš ï¸ Strategy Error: {e}, Defaulting to full search.")
            return SearchStrategy(rationale="Error in strategy planning", databases=["law", "admrul", "prec"])

    def _clean_keywords(self, keywords: List[str]) -> List[str]:
        cleaned = []
        for k in keywords:
            k = re.sub(r'\(.*?\)', '', k)
            k = re.sub(r'\s*ì œ\d*O*ì¡°.*', '', k)
            k = re.sub(r'[a-zA-Z]', '', k)
            k = k.strip()
            if len(k) >= 2: cleaned.append(k)
        return cleaned

    async def _generate_ai_queries(self, action: AtomicAction) -> List[str]:
        # Generate natural language queries for AI Search
        prompt = self.AI_QUERY_PROMPT.format(action=action.action)
        response = await llm_client.generate("", prompt, model="gpt-4o-mini", max_tokens=256)
        try:
            return json_repair.loads(response)[:3]
        except:
            return [action.action]

    async def _expand_query(self, action: AtomicAction) -> List[str]:
        # Legacy Keyword Extraction (still useful for Precedents)
        prompt = self.EXPANSION_PROMPT.format(action=f"{action.action}", object=action.object)
        response = await llm_client.generate("", prompt, model="gpt-4o-mini", max_tokens=256)
        try:
            parsed = json_repair.loads(response)
            return self._clean_keywords(parsed if isinstance(parsed, list) else [str(parsed)])[:5]
        except:
            return []

    async def _generate_prec_keywords(self, action: AtomicAction) -> List[str]:
        # 2. íŒë¡€/ì •ë°€ ê²€ìƒ‰ìš© êµ¬ì²´ì  í‚¤ì›Œë“œ ì¶”ì¶œ
        prompt = self.KEYWORD_GEN_PROMPT.format(action=action.action)
        response = await llm_client.generate(prompt, "", model="gpt-4o-mini", max_tokens=256)
        try:
            parsed = json_repair.loads(response)
            return self._clean_keywords(parsed if isinstance(parsed, list) else [str(parsed)])[:5]
        except:
            return []

    async def _select_best_candidates(self, candidates: List[Dict[str, Any]], action_text: str) -> List[Dict[str, Any]]:
        if not candidates: return []
        
        # [OPTIMIZATION] LLMì—ê²Œ ë„ˆë¬´ ë§ì€ í›„ë³´ë¥¼ ì£¼ë©´ ì²˜ë¦¬ ëª»í•¨. ìƒìœ„ 30ê°œë¡œ ì œí•œ
        if len(candidates) > 30:
            print(f"      âš ï¸ [Selector] í›„ë³´ {len(candidates)}ê°œ â†’ 30ê°œë¡œ ì œí•œ")
            candidates = candidates[:30]

        # LLMì—ê²Œ í›„ë³´êµ° ì „ë‹¬í•˜ì—¬ ì„ íƒ ìš”ì²­
        candidate_names = [c.get('ë²•ë ¹ëª…í•œê¸€') or c.get('í–‰ì •ê·œì¹™ëª…') for c in candidates]
        
        print(f"      ğŸ“‹ [Selector] {len(candidates)}ê°œ í›„ë³´ì—ì„œ ì„ íƒ ì¤‘...")
        print(f"      ğŸ“œ [í›„ë³´ ëª©ë¡]:")
        for i, name in enumerate(candidate_names[:10], 1):  # ì²˜ìŒ 10ê°œë§Œ ì¶œë ¥
            print(f"         {i}. {name}")
        if len(candidate_names) > 10:
            print(f"         ... ì™¸ {len(candidate_names) - 10}ê°œ")
        
        system_prompt = self.SELECTOR_PROMPT
        user_input_prompt = f"""
Candidate Count: {len(candidate_names)}

[User Action/Scenario]
{action_text}

[List of Candidates]
{chr(10).join([f"{i+1}. {name}" for i, name in enumerate(candidate_names)])}
"""
        
        # print(f"      ğŸ“‹ [DEBUG] Selector Prompt:\n{user_input_prompt[:500]}...\n")  # í”„ë¡¬í”„íŠ¸ ì¼ë¶€ ì¶œë ¥ (Verbose)
        
        try:
            # [MODEL: GPT-4o-mini] ëª©ë¡ ì¤‘ ì„ íƒ(Selection)ì€ minië„ ì˜í•¨
            response = await llm_client.generate(system_prompt, user_input_prompt, model="gpt-4o-mini", max_tokens=1024)
            
            print(f"      ğŸ” [Selector] LLM ì „ì²´ ì‘ë‹µ:\n{response}\n")  # ì „ì²´ ì‘ë‹µ ì¶œë ¥
            
            selected_names = json_repair.loads(response)
            if not isinstance(selected_names, list): selected_names = [str(selected_names)]

            print(f"      ğŸ¤– [Selector] LLM ì„ íƒ: {selected_names}")

            final_items = []
            for name in selected_names:
                # ì´ë¦„ì´ ì¼ì¹˜í•˜ëŠ” ì•„ì´í…œ ì°¾ê¸° (ë¶€ë¶„ ì¼ì¹˜ (in)ëŠ” ìœ„í—˜í•  ìˆ˜ ìˆìœ¼ë‹ˆ, ìµœëŒ€í•œ ì •í™•íˆ ë§¤ì¹­ ì‹œë„)
                for item in candidates:
                    item_name = item.get('ë²•ë ¹ëª…í•œê¸€') or item.get('í–‰ì •ê·œì¹™ëª…')
                    # LLMì´ ì´ë¦„ì„ ì¡°ê¸ˆ ì˜ë¼ì„œ ë§í•  ìˆ˜ë„ ìˆìœ¼ë¯€ë¡œ contains ì²´í¬
                    if name in item_name or item_name in name:
                        final_items.append(item)
                        break
            
            if not final_items:
                print(f"      âš ï¸ [Selector] ë§¤ì¹­ ì‹¤íŒ¨. ìƒìœ„ 10ê°œ ì‚¬ìš© (Fallback)")
                return candidates[:10]
            
            return final_items
        except Exception as e:
            print(f"      âš ï¸ Selector Error: {e}")
            return candidates[:10]

    async def _critique(self, action_text: str, evidence: List[str]) -> Dict[str, Any]:
        summary = "\n".join(evidence) if evidence else "None"
        prompt = self.CRITIC_PROMPT.format(action=action_text, evidence_summary=summary)
        # [MODEL: GPT-4o-mini] Critic í‰ê°€ (ë¹„ìš© ì ˆê°)
        response = await llm_client.generate(prompt, "", model="gpt-4o-mini", max_tokens=512)
        try:
            val = json_repair.loads(response)
            if not isinstance(val, dict): return {"status": "PASS", "new_keywords": []}
            return val
        except:
            return {"status": "PASS", "new_keywords": []}

    async def _search_phase(self, keywords: List[str], prec_keywords: List[str], action: AtomicAction, strategy: SearchStrategy, on_log: Optional[Callable[[str], Any]] = None) -> List[Tuple[str, str, str, str, Any]]:
        collected_raw_data = []
        found_law_titles = []
        
        async def log(msg):
            if on_log: await on_log(msg)

        # Merge focus keywords from strategy
        if strategy.focus_keywords:
            keywords.extend(strategy.focus_keywords)
            prec_keywords.extend(strategy.focus_keywords)
            
        target_dbs = strategy.databases
        await log(f"      ğŸ¯ [ì „ëµ] ëŒ€ìƒ DB: {target_dbs}")

        # [Phase 1] AI Search (Law & AdmRul)
        if 'law' in target_dbs or 'admrul' in target_dbs:
            # 1. Generate Intelligent Queries
            # If keywords are provided (e.g., from critic retry), use them, otherwise generate new AI queries.
            ai_queries = keywords if keywords else await self._generate_ai_queries(action)
            await log(f"      ğŸ“¡ [AI ê²€ìƒ‰] ì§ˆì˜ì–´: {ai_queries}")
            
            if not ai_queries: ai_queries = [action.action]
            
            search_tasks = []
            for q in ai_queries:
                if 'law' in target_dbs:
                    search_tasks.append(law_api.ai_search(q, 0)) # Scope 0: Law
                if 'admrul' in target_dbs:
                    search_tasks.append(law_api.ai_search(q, 2)) # Scope 2: AdmRul

            if search_tasks:
                results_list = await asyncio.gather(*search_tasks)
                
                cnt_total = 0
                for results in results_list:
                    for item in results:
                        # item keys: law_name, article_title, content, link, raw
                        # Use 'ai_result' category to skip complex structure parsing
                        collected_raw_data.append(('ai_result', f"{item['law_name']} {item['article_title']}", item['content'], item['link'], item['raw']))
                        found_law_titles.append(item['law_name'])
                        cnt_total += 1
                
                await log(f"        -> AI ë²•ë ¹/ê·œì¹™ ê²€ìƒ‰ ì™„ë£Œ: {cnt_total}ê°œ ì¡°í•­ í™•ë³´")

        # [Phase 2] Precedent Search (Legacy)
        # AI Search API (search=0,1,2,3) generally covers Statutes/Rules. Precedents ('prec') often require separate handling.
        if 'prec' in target_dbs:
            await log(f"      ğŸ“¡ íŒë¡€ ê²€ìƒ‰ ìˆ˜í–‰ ì¤‘...")
            
            prec_tasks = []
            
            # Use found law titles as filter (JO) if available, plus global search
            unique_law_titles = list(set(found_law_titles))
            
            # Strategy 1: Law + Keyword
            for title in unique_law_titles[:2]: 
                for kw in prec_keywords:
                    prec_tasks.append(law_api.search_list('prec', query=kw, JO=title, display=30))

            # Strategy 2: Global Keyword
            for kw in prec_keywords:
                prec_tasks.append(law_api.search_list('prec', query=kw, display=30))

            prec_results = []
            if prec_tasks:
                prec_results = await asyncio.gather(*prec_tasks)

            prec_candidates = []
            seen_prec_ids = set()
            
            for res in prec_results:
                for item in res: 
                    p_id = item.get('íŒë¡€ì¼ë ¨ë²ˆí˜¸')
                    if p_id and p_id not in seen_prec_ids:
                        seen_prec_ids.add(p_id)
                        item['ë²•ë ¹ëª…í•œê¸€'] = f"[íŒë¡€] {item.get('íŒë¡€ë‚´ìš©') or item.get('ì‚¬ê±´ëª…')}"
                        prec_candidates.append(item)
            
            # Selector for Precedents
            if prec_candidates:
                target_precs = await self._select_best_candidates(prec_candidates[:30], action.action)
            else:
                target_precs = []
            
            await log(f"      ğŸ‘‰ íŒë¡€ ë³¸ë¬¸ ì¡°íšŒ: {len(target_precs)}ê±´")

            prec_fetch_tasks = [law_api.get_content_from_item(item) for item in target_precs]
            if prec_fetch_tasks:
                prec_contents = await asyncio.gather(*prec_fetch_tasks)
                for item, (content, url, raw_data) in zip(target_precs, prec_contents):
                    title = item.get('ë²•ë ¹ëª…í•œê¸€')
                    collected_raw_data.append(('prec', title, content, url, raw_data))

        # [Limit] Max Documents
        if len(collected_raw_data) > MAX_ANALYSIS_DOCS:
            await log(f"ìë£Œ ìµœì í™”: ìˆ˜ì§‘ëœ {len(collected_raw_data)}ê±´ ì¤‘ ìƒìœ„ {MAX_ANALYSIS_DOCS}ê±´ ë¶„ì„ ì§„í–‰")
            collected_raw_data = collected_raw_data[:MAX_ANALYSIS_DOCS]

        return collected_raw_data

    async def _analyze_full_text(self, text: str, action: AtomicAction, category: str, title: str, url: str, raw_data: Any) -> List[DocumentReview]:
        """
        ë¬¸ì„œ ì „ì²´ë¥¼ ìˆœíšŒí•˜ë©° í•µì‹¬ ë‚´ìš© ì¶”ì¶œ
        category='ai_result' ì¸ ê²½ìš° ì´ë¯¸ ì¡°í•­ ë‹¨ìœ„ì´ë¯€ë¡œ ë°”ë¡œ ë¶„ì„.
        """
        # [Cache]
        if category == 'ai_result':
             # Use article title + law name hash or link
             # raw_data is the item dict from ai_search
             doc_id = f"AI_{title}_{url}"
        else:
             doc_id = law_api._get_unique_id(raw_data)
             if doc_id == "Unknown": doc_id = f"{title}_{url}"
            
        cache_key = (action.action, doc_id)
        
        if cache_key in self._analysis_cache:
            cached_reviews = self._analysis_cache[cache_key]
            for r in cached_reviews: r.url = url
            return cached_reviews

        reviews = []
        full_action_context = f"[{action.actor}] {action.action} (ëŒ€ìƒ: {action.object})"
        
        # [Optimization] If ai_result, skip structure parsing/index scanning
        if category == 'ai_result':
            # Direct Analysis
            prompt = f"""
            [Analysis Target: {title}]
            {text}

            [User Action Context]
            {full_action_context}

            Extract legal grounds related to the 'User Action Context' from this specific article.
            
            [Target Schema]
            {{
                "law_name": "{title.split(' ')[0]}", 
                "key_clause": "{title.split(' ')[1] if ' ' in title else 'ì¡°í•­'}",
                "status": "Prohibited | Permitted | Conditional | Neutral | Ambiguous",
                "summary": "í•´ë‹¹ ì¡°í•­ì˜ í•µì‹¬ ë‚´ìš© ìš”ì•½ (í•œê¸€ 2ë¬¸ì¥ ì´ë‚´)"
            }}
            If irrelevant, set status to 'Neutral'.
            """
            res = await llm_client.generate(prompt, "Analyze this article.", model="gpt-4o-mini", max_tokens=512)
            try:
                data = json_repair.loads(res)
                if data.get('status') != 'Neutral':
                    rev = DocumentReview(**data)
                    rev.url = url
                    reviews.append(rev)
            except:
                pass
            
            self._analysis_cache[cache_key] = reviews
            return reviews

        # Existing Logic for Legacy (Full Text / Precedents)
        if category in ['law', 'admrul', 'prec']:
            articles = law_api._parse_law_structure(raw_data)
            
            # Case 1: íŒë¡€ (Precedent) - êµ¬ì¡° ë¶„ì„ ê²°ê³¼ê°€ ìˆë‹¤ë©´ í•­ìƒ ì‚¬ìš© (í° í…ìŠ¤íŠ¸ ë°©ì§€)
            if category == 'prec' and articles:
                 # íŒë¡€ëŠ” [íŒì‹œì‚¬í•­, íŒê²°ìš”ì§€] ë§Œìœ¼ë¡œ êµ¬ì„±í•˜ì—¬ ì¬ë¶„ì„
                 # print(f"      âš–ï¸ [Precedent] íŒë¡€ êµ¬ì¡° ë¶„ì„ (íŒì‹œì‚¬í•­/íŒê²°ìš”ì§€ ìœ„ì£¼)")
                 combined_text = "\n\n".join([f"[{a['id']}]\n{a['content']}" for a in articles])
                 # ì¬ê·€ í˜¸ì¶œí•˜ì—¬ ì§§ì€ í…ìŠ¤íŠ¸ ë¡œì§ìœ¼ë¡œ ì²˜ë¦¬
                 return await self._analyze_full_text(combined_text, action, category, title, url, {}) 

            # Case 2: ë²•ë ¹/í–‰ì •ê·œì¹™ - ì¡°ë¬¸ì´ ë„ˆë¬´ ë§ìœ¼ë©´ ëª©ì°¨ ìŠ¤ìºë‹ ìˆ˜í–‰
            if len(articles) > 5:
                # ì¡°ë¬¸ì´ ë„ˆë¬´ ë§ìœ¼ë©´ (ì˜ˆ: 5ê°œ ì´ìƒ) ëª©ì°¨ ìŠ¤ìºë‹ ìˆ˜í–‰
                print(f"      ğŸ“‘ [Index Scan] {title} - ì´ {len(articles)}ê°œ ì¡°ë¬¸ ì¤‘ ê´€ë ¨ ì¡°í•­ ì„ ë³„ ì¤‘...")
                
                # 1. ëª©ì°¨(ì œëª©)ë§Œ ì¶”ì¶œ
                toc_text = "\n".join([f"{i}. {art['id']}" for i, art in enumerate(articles)])
                
                print(f"        -> ë¶„ì„ ëŒ€ìƒ í–‰ìœ„: {action.action[:100]}...")  # ë””ë²„ê¹…ìš©
                
                prompt = f"""
You are analyzing a legal document to find relevant articles for a specific business action.

[Document: {title}]
[Table of Contents]
{toc_text}

[Business Action to Analyze]
{full_action_context}

Task:
1. Review the table of contents above
2. Identify which articles are MOST relevant to the business action
3. Select up to 5 article indices (numbers only)
4. If NO articles seem relevant, return an empty list: []

Output Format (JSON array of numbers):
[0, 5, 12]

Important:
- Only select articles that are DIRECTLY related to the business action
- If unsure or no clear match, return []
- Be strict in selection to avoid irrelevant articles
"""
                
                # [MODEL: GPT-4o-mini] ëª©ì°¨ ìŠ¤ìºë‹
                # System Promptì— ì§€ì¹¨ì„ ë„£ê³ , User Inputì€ ê°„ë‹¨í•˜ê²Œ "ë¶„ì„ ì‹œì‘" ì •ë„ë¡œ ì²˜ë¦¬
                res = await llm_client.generate(prompt, "Analyze the specific business action against the table of contents.", model="gpt-4o-mini", max_tokens=256)
                try:
                    selected_indices = json_repair.loads(res)
                    if not isinstance(selected_indices, list): selected_indices = []
                    
                    print(f"        -> LLM ì„ ë³„ ê²°ê³¼: {selected_indices}")
                    
                    target_articles = [articles[i] for i in selected_indices if isinstance(i, int) and 0 <= i < len(articles)]
                    
                    if target_articles:
                        print(f"        -> ì„ ë³„ëœ ì¡°í•­: {[a['id'] for a in target_articles]}")
                        # [NEW] ì„ ë³„ëœ ì¡°í•­ì„ ê°œë³„ì ìœ¼ë¡œ ë¶„ì„ (chunking ë°©ì§€)
                        for art in target_articles:
                            art_prompt = f"""
                            [Analysis Target: {category} - {title}]
                            [{art['id']}]
                            {art['content']}

                            [User Action Context]
                            {full_action_context}

                            Extract legal grounds related to the 'User Action Context' from the text and respond in JSON.
                            
                            [Target Schema]
                            {{
                                "law_name": "{title}",
                                "key_clause": "{art['id']}",
                                "status": "Prohibited | Permitted | Conditional | Neutral | Ambiguous",
                                "summary": "í•´ë‹¹ ì¡°í•­ì˜ í•µì‹¬ ë‚´ìš© ìš”ì•½ (í•œê¸€ 2ë¬¸ì¥ ì´ë‚´)"
                            }}
                            If there is no relevant content at all, set the status to 'Neutral'.
                            """
                            art_res = await llm_client.generate(art_prompt, "Analyze this article.", model="gpt-4o-mini", max_tokens=512)
                            try:
                                art_data = json_repair.loads(art_res)
                                if art_data.get('status') != 'Neutral':
                                    rev = DocumentReview(**art_data)
                                    rev.url = url
                                    reviews.append(rev)
                            except:
                                pass
                        
                        # ìºì‹œ ì €ì¥ í›„ ë°˜í™˜ (chunking ë‹¨ê³„ë¡œ ê°€ì§€ ì•ŠìŒ)
                        self._analysis_cache[cache_key] = reviews
                        return reviews
                    else:
                        # [Critical Fix] ì¸ë±ìŠ¤ ìŠ¤ìº” ê²°ê³¼ "ê´€ë ¨ ì—†ìŒ"ì´ë©´ ê³¼ê°í•˜ê²Œ Skip (ë¬´ì‘ì • ì²­í‚¹ ë°©ì§€)
                        print(f"        ğŸš« [Index Scan] '{title}'ì—ì„œ ê´€ë ¨ ì¡°í•­ ë°œê²¬ë˜ì§€ ì•ŠìŒ -> ë¶„ì„ ì¢…ë£Œ.")
                        self._analysis_cache[cache_key] = []
                        return []
                except Exception as e:
                    print(f"        âš ï¸ Index Scan Error: {e}, Falling back to chunking.")
                    pass # ì‹¤íŒ¨í•˜ë©´ ì•„ë˜ ì²­í¬ ë¡œì§ìœ¼ë¡œ ë„˜ì–´ê°

        # 1. í…ìŠ¤íŠ¸ê°€ ì§§ìœ¼ë©´ ë°”ë¡œ ë¶„ì„
        if len(text) < 5000:
            prompt = f"""
            [Analysis Target: {category} - {title}]
            {text}

            [User Action Context]
            {full_action_context}

            Extract legal grounds related to the 'User Action Context' from the text and respond in JSON.
            
            [Target Schema]
            {{
                "law_name": "{title}",
                "key_clause": "ê´€ë ¨ ì¡°í•­ (ì˜ˆ: ì œ3ì¡° ì œ1í•­) ì—†ìœ¼ë©´ ë¹ˆì¹¸",
                "status": "ê¸ˆì§€ | í—ˆìš© | ì¡°ê±´ë¶€ | ì¤‘ë¦½ | ë¶ˆëª…í™•",
                "summary": "í•´ë‹¹ ì¡°í•­ì˜ í•µì‹¬ ë‚´ìš© ìš”ì•½ (í•œê¸€ 2ë¬¸ì¥ ì´ë‚´)"
            }}
            If there is no relevant content at all, set the status to 'ì¤‘ë¦½'.
            """
            # [MODEL: GPT-4o-mini] ì½ì–´ì•¼ í•  ì–‘ì´ ê°€ì¥ ë§ì€ ë¶€ë¶„. mini ì‚¬ìš© í•„ìˆ˜ (ë¹„ìš© ì ˆê°)
            res = await llm_client.generate(prompt, "Analyze this text for legal risks.", model="gpt-4o-mini", max_tokens=512)
            try:
                data = json_repair.loads(res)
                if data.get('status') != 'ì¤‘ë¦½':
                    rev = DocumentReview(**data)
                    rev.url = url
                    reviews.append(rev)
            except:
                pass
            return reviews

        # 2. í…ìŠ¤íŠ¸ê°€ ê¸¸ë©´ ë¶„í•  ì²˜ë¦¬ (Chunking) - Full Scan
        chunk_size = 4000
        overlap = 300
        chunks = [text[i:i+chunk_size] for i in range(0, len(text), chunk_size - overlap)]
        
        print(f"      ğŸ§© [Chunking] {title} - {len(chunks)}ê°œ ì¡°ê°ìœ¼ë¡œ ë¶„í•  ë¶„ì„ ì¤‘...")

        tasks = []
        for i, chunk in enumerate(chunks):
            prompt = f"""
            [Analysis Target: {category} - {title} (Part {i+1}/{len(chunks)})]
            {chunk}

            [User Action Context]
            {full_action_context}

            If there are legal grounds (prohibition, permission, penalty, etc.) related to the 'User Action Context' in this text chunk, extract them.
            If it's difficult to judge due to broken context, set the status to 'Neutral'.
            
            [Target Schema]
            {{
                "law_name": "{title}",
                "key_clause": "ì¡°í•­ ë²ˆí˜¸",
                "status": "Prohibited | Permitted | Conditional | Neutral",
                "summary": "ìš”ì•½"
            }}
            """
            # [MODEL: GPT-4o-mini] ëŒ€ëŸ‰ì˜ Chunk ì²˜ë¦¬
            tasks.append(llm_client.generate(prompt, "Analyze this chunk for legal relevance.", model="gpt-4o-mini", max_tokens=512))

        results = await asyncio.gather(*tasks)

        for res in results:
            try:
                data = json_repair.loads(res)
                if data.get('status') != 'Neutral':
                     # ì¤‘ë³µ ì œê±° (ê°™ì€ ì¡°í•­ì´ ì—¬ëŸ¬ ì²­í¬ì— ê±¸ì¹  ìˆ˜ ìˆìŒ)
                     rev = DocumentReview(**data)
                     rev.url = url
                     reviews.append(rev)
            except:
                pass
        
        # [Cache] ê²°ê³¼ ì €ì¥
        self._analysis_cache[cache_key] = reviews
        return reviews

    async def _extract_evidence(self, raw_data: List[Tuple[str, str, str, str, Any]], action: AtomicAction) -> List[DocumentReview]:
        if not raw_data: return []
        
        doc_count = len(raw_data)
        doc_titles = [f"[{c}] {t}" for c, t, _, _, _ in raw_data[:5]]
        etc_text = f" ì™¸ {doc_count-5}ê±´" if doc_count > 5 else ""

        print(f"\n      ğŸ“ [ì •ë°€ ë¶„ì„] ì´ {doc_count}ê±´ì˜ ë¬¸ê±´ì„ ì „ìˆ˜ ì¡°ì‚¬í•©ë‹ˆë‹¤. (LLM Reading...)")
        print(f"         ëŒ€ìƒ: {', '.join(doc_titles)}{etc_text}")
        
        tasks = []
        valid_reviews = []

        for category, title, text, url, raw_data_item in raw_data:
            if not text or len(text) < 50: continue
            # [Update] ì „ì²´ í…ìŠ¤íŠ¸ ë¶„ì„ ìš”ì²­ (List[DocumentReview] ë°˜í™˜)
            tasks.append(self._analyze_full_text(text, action, category, title, url, raw_data_item))

        if tasks:
            results = await asyncio.gather(*tasks)
            for res_list in results:
                # ê²°ê³¼ê°€ ë¦¬ìŠ¤íŠ¸ì´ë¯€ë¡œ í™•ì¥
                valid_reviews.extend(res_list)

        return valid_reviews

    async def _process_action(self, action: AtomicAction) -> List[DocumentReview]:
        print(f"\n  ğŸ¬ [Action ì‹œì‘] {action.action}")

        # 1. Keyword Generation
        # law_names = await self._expand_query(action) # Legacy unused
        
        # New AI Queries used inside _search_phase
        prec_keywords = await self._generate_prec_keywords(action)
        print(f"    1ï¸âƒ£  [íŒë¡€ í‚¤ì›Œë“œ]: {prec_keywords}")

        # 1.5 Strategy Planning
        strategy = await self._plan_search(action)
        print(f"    ğŸ§  [ì „ëµ ìˆ˜ë¦½] {strategy.rationale}")
        print(f"       -> ëŒ€ìƒ DB: {strategy.databases} | í•µì‹¬ì–´: {strategy.focus_keywords}")

        final_evidence = []

        # 2. Loop (Initial + Retry)
        max_retries = 1
        for attempt in range(max_retries + 1):
            is_retry = attempt > 0
            prefix = "ğŸ”„ [ì¬ê²€ìƒ‰]" if is_retry else "ğŸš€ [1ì°¨ ê²€ìƒ‰]"
            print(f"    {prefix} ì‹œì‘...")

            # Search
            # Pass new_kws from critic as 'keywords' argument to _search_phase for AI search override
            current_ai_keywords = critic_res.get('new_keywords', []) if is_retry else []
            raw_data = await self._search_phase(current_ai_keywords, prec_keywords, action, strategy)

            # Extract (Structured)
            new_reviews = await self._extract_evidence(raw_data, action)
            
            # Deduplicate by law_name + key_clause
            existing_keys = set(f"{r.law_name}-{r.key_clause}" for r in final_evidence)
            for r in new_reviews:
                key = f"{r.law_name}-{r.key_clause}"
                if key not in existing_keys:
                    final_evidence.append(r)
                    existing_keys.add(key)

            # Critique (Needs string for criticism)
            evidence_summary = [f"[{r.status}] {r.law_name} {r.key_clause}: {r.summary}" for r in final_evidence]
            critic_res = await self._critique(action.action, evidence_summary)
            print(f"      ğŸ§ [Critic í‰ê°€] {critic_res.get('status')} : {critic_res.get('reason')}")

            if critic_res.get('status') == 'PASS':
                print("      -> ì¶©ë¶„í•œ ê·¼ê±° í™•ë³´. ê²€ìƒ‰ ì¢…ë£Œ.")
                break

            if is_retry:
                print("      -> ì¬ê²€ìƒ‰í–ˆìœ¼ë‚˜ ì—¬ì „íˆ ë¶€ì¡±í•¨. ì¢…ë£Œ.")
                break

            # Prepare Retry
            new_kws = critic_res.get('new_keywords', [])
            if new_kws:
                print(f"      -> âš ï¸ ë¶€ì¡±í•¨! Critic ì œì•ˆ í‚¤ì›Œë“œë¡œ ì¬ì‹œë„: {new_kws}")
                # The `current_ai_keywords` will be set in the next loop iteration.
            else:
                break

        print(f"      -> âœ… ìµœì¢… í™•ë³´ëœ ê·¼ê±°: {len(final_evidence)}ê±´")
        return final_evidence

    async def execute(self, scenario: Scenario, on_log: Optional[Callable[[str], Any]] = None) -> Tuple[LegalEvidence, List[DocumentReview]]:
        async def log(msg):
            if on_log: await on_log(msg)
            
        await log(f"\n[3-1] Investigator: Analyzing '{scenario.name}'...")
        
        # 1. Action ë¶„í•´ ë° ê²€ìƒ‰ ì „ëµ ìˆ˜ë¦½
        all_reviews = []
        
        for action in scenario.actions:
            await log(f"\n    ğŸ” ë²•ë¥  ìŸì  ë¶„ì„ ì¤‘: {action.action}")
            
            # (1) ê²€ìƒ‰ ì „ëµ ìˆ˜ë¦½
            strategy = await self._plan_search(action)
            await log(f"ê²€ìƒ‰ ì „ëµ ìˆ˜ë¦½ ì™„ë£Œ: {strategy.rationale}")
            
            # (2) í‚¤ì›Œë“œ í™•ì¥ (AI Search í™œìš©ì„ ìœ„í•´ ì´ˆê¸° í‚¤ì›Œë“œëŠ” ë¹„ì›Œë‘  -> _search_phaseì—ì„œ ìƒì„±)
            keywords = []
            prec_keywords = await self._generate_prec_keywords(action)
            
            # (3) ê²€ìƒ‰ ë° ë²•ì  ê·¼ê±° ì¶”ì¶œ (Retry ë¡œì§ í¬í•¨)
            raw_data = await self._search_phase(keywords, prec_keywords, action, strategy, on_log=on_log)
            
            # Count Types (ai_result integrated)
            cnt_ai = sum(1 for r in raw_data if r[0] == 'ai_result')
            cnt_prec = sum(1 for r in raw_data if r[0] == 'prec')
            
            await log(f"ë²•ë ¹ ìë£Œ ìˆ˜ì§‘: AIê²€ìƒ‰ {cnt_ai}ê±´ (ë²•ë ¹/ê·œì¹™), íŒë¡€ {cnt_prec}ê±´")

            reviews = await self._extract_evidence(raw_data, action)
            
            # (4) ê²€ì¦ (Critic)
            docs_text = [r.summary for r in reviews]
            critique = await self._critique(action.action, docs_text)
            
            if critique.get("status") == "RETRY":
                await log(f"ì¶”ê°€ ê²€ìƒ‰ í•„ìš”: {critique.get('reason')}")
                # print(f"      ğŸ”„ ì¬ê²€ìƒ‰ ìš”ì²­: {critique.get('reason')}")
                new_kws = critique.get("new_keywords", [])
                # ê°„ë‹¨íˆ ì¶”ê°€ ê²€ìƒ‰ ìˆ˜í–‰ (Strategy ë¬´ì‹œí•˜ê³  í‚¤ì›Œë“œ ì¤‘ì‹¬)
                raw_data_retry = await self._search_phase(new_kws, new_kws, action, strategy, on_log=on_log)
                reviews_retry = await self._extract_evidence(raw_data_retry, action)
                reviews.extend(reviews_retry)

            all_reviews.extend(reviews)

        # ì¤‘ë³µ ì œê±°
        unique_reviews = []
        seen = set()
        for r in all_reviews:
            key = (r.law_name, r.key_clause)
            if key not in seen:
                seen.add(key)
                unique_reviews.append(r)
        
        # [Limit] Hard limit to 50 (Total)
        if len(unique_reviews) > 50:
            unique_reviews = unique_reviews[:50]
            
        evidence_summary = [f"- {r.law_name} {r.key_clause}: {r.summary}" for r in unique_reviews]
        return LegalEvidence(relevant_laws=evidence_summary, summary=""), unique_reviews
